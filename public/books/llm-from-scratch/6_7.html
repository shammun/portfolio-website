<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Spam Classification Pipeline</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #fafbff 0%, #f5f7ff 100%);
            min-height: 100vh;
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        /* Header */
        header {
            text-align: center;
            margin-bottom: 30px;
        }

        header h1 {
            font-size: 1.8rem;
            margin-bottom: 4px;
            font-weight: 700;
            color: #1e293b;
        }

        header p {
            font-size: 0.95rem;
            color: #64748b;
        }

        /* Example Selector */
        .example-selector {
            background: white;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
        }

        .example-selector h3 {
            margin-bottom: 15px;
            color: #333;
            font-size: 1.1em;
        }

        .example-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 10px;
        }

        .example-btn {
            padding: 12px 16px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            background: white;
            cursor: pointer;
            transition: all 0.3s;
            text-align: left;
            font-size: 0.9em;
        }

        .example-btn:hover {
            border-color: #764ba2;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(118, 75, 162, 0.2);
        }

        .example-btn.active {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-color: #764ba2;
        }

        .example-preview {
            font-size: 0.85em;
            opacity: 0.8;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .custom-input-area {
            margin-top: 10px;
            display: none;
        }

        .custom-input-area.active {
            display: block;
        }

        .custom-input-area textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-family: inherit;
            resize: vertical;
            min-height: 80px;
        }

        .char-count {
            text-align: right;
            font-size: 0.85em;
            color: #666;
            margin-top: 5px;
        }

        /* Step Navigation */
        .step-navigation {
            background: white;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
            overflow-x: auto;
        }

        .step-nav-scroll {
            display: flex;
            gap: 12px;
            min-width: min-content;
        }

        .step-card {
            min-width: 140px;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            text-align: center;
            background: white;
        }

        .step-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .step-card.active {
            border-color: #ff9800;
            box-shadow: 0 4px 12px rgba(255, 152, 0, 0.3);
        }

        .step-card.active.input-phase {
            border-color: #ff9800;
            background: rgba(255, 152, 0, 0.05);
        }

        .step-card.active.processing-phase {
            border-color: #764ba2;
            background: rgba(118, 75, 162, 0.05);
        }

        .step-card.active.output-phase {
            border-color: #00bcd4;
            background: rgba(0, 188, 212, 0.05);
        }

        .step-number {
            font-size: 1.5em;
            font-weight: 700;
            margin-bottom: 5px;
        }

        .step-icon {
            font-size: 1.3em;
            margin-bottom: 5px;
        }

        .step-title {
            font-size: 0.85em;
            color: #666;
        }

        /* Control Toolbar */
        .control-toolbar {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-bottom: 20px;
        }

        .control-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            background: white;
            color: #764ba2;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .control-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
        }

        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        /* Main Grid */
        .main-grid {
            display: grid;
            grid-template-columns: 1.3fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }

        .visualization-panel,
        .info-panel {
            background: white;
            border-radius: 12px;
            padding: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
        }

        .visualization-panel {
            height: 480px;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        #visualization-svg {
            width: 100%;
            height: 100%;
        }

        .info-panel {
            display: flex;
            flex-direction: column;
            height: 480px;
        }

        .explanation-area {
            flex: 1;
            overflow-y: auto;
            margin-bottom: 15px;
            padding-right: 10px;
        }

        .explanation-area h2 {
            color: #333;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        .explanation-area p {
            margin-bottom: 12px;
            color: #555;
        }

        .explanation-area ul {
            margin-left: 20px;
            margin-bottom: 12px;
        }

        .explanation-area li {
            margin-bottom: 6px;
            color: #555;
        }

        .key-insight {
            background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            border-left: 4px solid #2196f3;
            padding: 12px;
            margin: 15px 0;
            border-radius: 6px;
        }

        .key-insight strong {
            color: #1976d2;
        }

        .code-snippet {
            border-top: 2px solid #e2e8f0;
            background: #1e293b;
            flex-shrink: 0;
            position: relative;
        }

        .code-header {
            background: #0f172a;
            padding: 6px 12px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid #334155;
        }

        .code-header-title {
            color: #94a3b8;
            font-size: 0.75rem;
            font-weight: 600;
        }

        .code-snippet pre {
            margin: 0;
            background: transparent;
            padding: 8px 12px;
            overflow-y: auto;
            max-height: 120px;
        }

        .code-snippet code {
            font-size: 0.75rem;
            line-height: 1.3;
        }

        .view-full-code {
            background: #8b5cf6;
            color: white;
            border: none;
            padding: 4px 12px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .view-full-code:hover {
            background: #7c3aed;
            transform: translateY(-1px);
        }

        /* Modal */
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            z-index: 1000;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .modal.active {
            display: flex;
        }

        .modal-content {
            background: #1e293b;
            border-radius: 12px;
            width: 90%;
            max-width: 1000px;
            max-height: 90vh;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        .modal-header {
            background: #0f172a;
            padding: 16px 20px;
            border-bottom: 2px solid #8b5cf6;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .modal-header h2 {
            color: #8b5cf6;
            font-size: 1.1rem;
            font-weight: 700;
            margin: 0;
        }

        .modal-close {
            background: #ef4444;
            color: white;
            border: none;
            padding: 6px 16px;
            border-radius: 6px;
            font-size: 0.85rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .modal-close:hover {
            background: #dc2626;
        }

        .modal-body {
            padding: 20px;
            overflow-y: auto;
        }

        .modal-body pre {
            background: transparent;
            border-radius: 0;
            padding: 0;
            margin: 0;
            overflow-x: auto;
        }

        .highlight-line {
            background: rgba(139, 92, 246, 0.25);
            border-left: 4px solid #8b5cf6;
            padding-left: 8px;
            display: block;
            margin: 2px 0;
        }

        /* Key Takeaways */
        .key-takeaways {
            background: white;
            border-radius: 12px;
            padding: 20px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
        }

        .key-takeaways h3 {
            color: #333;
            margin-bottom: 15px;
        }

        .key-takeaways ul {
            list-style: none;
        }

        .key-takeaways li {
            padding: 8px 0;
            padding-left: 25px;
            position: relative;
            color: #555;
        }

        .key-takeaways li:before {
            content: "‚úì";
            position: absolute;
            left: 0;
            color: #4caf50;
            font-weight: bold;
        }

        /* Responsive */
        @media (max-width: 1200px) {
            .main-grid {
                grid-template-columns: 1fr;
            }
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8em;
            }

            .step-nav-scroll {
                justify-content: flex-start;
            }

            .example-grid {
                grid-template-columns: 1fr;
            }
        }

        /* Phase Colors */
        .phase-orange { color: #ff9800; }
        .phase-purple { color: #764ba2; }
        .phase-teal { color: #00bcd4; }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header>
            <h1>Interactive Spam Classification Pipeline</h1>
            <p>Watch how a GPT model transforms text into predictions, step by step</p>
        </header>

        <!-- Example Selector -->
        <div class="example-selector">
            <h3>Select an Example Message</h3>
            <div class="example-grid">
                <button class="example-btn active" data-example="0">
                    <div><strong>Example 1: Spam</strong></div>
                    <div class="example-preview">You are a winner you have been...</div>
                </button>
                <button class="example-btn" data-example="1">
                    <div><strong>Example 2: Not Spam</strong></div>
                    <div class="example-preview">Hey, just wanted to check if we're...</div>
                </button>
                <button class="example-btn" data-example="2">
                    <div><strong>Example 3: Spam</strong></div>
                    <div class="example-preview">URGENT! Your account will be...</div>
                </button>
                <button class="example-btn" data-example="3">
                    <div><strong>Example 4: Not Spam</strong></div>
                    <div class="example-preview">Meeting rescheduled to 3pm...</div>
                </button>
                <button class="example-btn" data-example="4">
                    <div><strong>Custom Input</strong></div>
                    <div class="example-preview">Type your own message</div>
                </button>
            </div>
            <div class="custom-input-area" id="customInputArea">
                <textarea id="customInput" placeholder="Type your message here..."></textarea>
                <div class="char-count" id="charCount">0 characters</div>
            </div>
        </div>

        <!-- Step Navigation -->
        <div class="step-navigation">
            <div class="step-nav-scroll" id="stepNavigation"></div>
        </div>

        <!-- Control Toolbar -->
        <div class="control-toolbar">
            <button class="control-btn" id="prevBtn">‚Üê Previous</button>
            <button class="control-btn" id="playBtn">‚ñ∂ Play</button>
            <button class="control-btn" id="nextBtn">Next ‚Üí</button>
        </div>

        <!-- Main Grid -->
        <div class="main-grid">
            <!-- Visualization Panel -->
            <div class="visualization-panel">
                <svg id="visualization-svg" viewBox="0 0 600 400"></svg>
            </div>

            <!-- Info Panel -->
            <div class="info-panel">
                <div class="explanation-area" id="explanationArea"></div>
                <div class="code-snippet">
                    <div class="code-header">
                        <span class="code-header-title">PyTorch Logic</span>
                        <button class="view-full-code" id="viewFullCodeBtn">View Full Code</button>
                    </div>
                    <pre><code class="language-python" id="codeSnippet"></code></pre>
                </div>
            </div>
        </div>

    </div>

    <!-- Modal -->
    <div class="modal" id="codeModal">
        <div class="modal-content">
            <div class="modal-header">
                <h2>üîç Complete classify_review Function</h2>
                <button class="modal-close" id="modalClose">‚úï Close</button>
            </div>
            <div class="modal-body">
                <pre><code class="language-python" id="fullCode"></code></pre>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        // State Management
        const state = {
            currentStep: 0,
            currentExample: 0,
            isPlaying: false,
            playInterval: null,
            examples: [
                {
                    text: "You are a winner you have been specially selected to receive $1000 cash or a $2000 award.",
                    label: "spam",
                    tokens: ["You", "are", "a", "winner", "you", "have", "been", "specially", "selected", "to", "receive", "$", "1000", "cash", "or", "a", "$", "2000", "award", "."],
                    tokenIds: [1342, 389, 257, 8464, 345, 423, 587, 5734, 6163, 284, 3328, 720, 16, 830, 5003, 393, 257, 720, 17, 830, 5764, 13]
                },
                {
                    text: "Hey, just wanted to check if we're still on for dinner tonight? Let me know!",
                    label: "not spam",
                    tokens: ["Hey", ",", "just", "wanted", "to", "check", "if", "we", "'re", "still", "on", "for", "dinner", "tonight", "?", "Let", "me", "know", "!"],
                    tokenIds: [10814, 11, 655, 2227, 284, 2198, 611, 356, 821, 991, 319, 329, 8073, 9975, 30, 3914, 502, 760, 0]
                },
                {
                    text: "URGENT! Your account will be closed. Click here immediately to verify your information.",
                    label: "spam",
                    tokens: ["URG", "ENT", "!", "Your", "account", "will", "be", "closed", ".", "Click", "here", "immediately", "to", "verify", "your", "information", "."],
                    tokenIds: [27203, 3525, 0, 3406, 1848, 481, 307, 4838, 13, 6914, 994, 3393, 284, 11767, 534, 1321, 13]
                },
                {
                    text: "Meeting rescheduled to 3pm tomorrow. See you in the conference room.",
                    label: "not spam",
                    tokens: ["Meeting", "rescheduled", "to", "3", "pm", "tomorrow", ".", "See", "you", "in", "the", "conference", "room", "."],
                    tokenIds: [33602, 37768, 284, 513, 4426, 9439, 13, 4091, 345, 287, 262, 4495, 2119, 13]
                },
                {
                    text: "",
                    label: "custom",
                    tokens: [],
                    tokenIds: []
                }
            ],
            steps: [
                {
                    id: 1,
                    icon: "üìù",
                    title: "Input Text",
                    phase: "input-phase",
                    explanation: `
                        <h2>üìù Input Text Message</h2>
                        <p>This is where everything begins. The user provides a raw text message that needs to be classified. This could be an SMS, email, or any text string. Notice that the text is just a regular Python string - the model can't understand text in this format yet.</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> The model operates in evaluation mode (<code>model.eval()</code>), which disables dropout and batch normalization layers to ensure consistent, deterministic predictions.
                        </div>
                    `,
                    code: `def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):
    """
    Classifies a given text message as either 'spam' or 'not spam' using a fine-tuned GPT model.
    
    Parameters:
    - text (str): The input message to classify.
    """
    model.eval()  # Sets the model to evaluation mode`
                },
                {
                    id: 2,
                    icon: "üî§",
                    title: "Tokenization",
                    phase: "input-phase",
                    explanation: `
                        <h2>üî§ Text ‚Üí Token IDs</h2>
                        <p>The tokenizer converts the raw text into a sequence of numerical token IDs. Each token represents a subword, word, or character depending on the tokenizer's vocabulary. For example, "iPhone" might become token ID 7133, while "now" becomes 783. This numerical representation is what the model actually processes.</p>
                        <p><strong>Why This Matters:</strong> Neural networks cannot process text directly - they need numbers. Tokenization bridges the gap between human language and machine understanding.</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> GPT uses byte-pair encoding (BPE) tokenization, which breaks text into subword units. Common words are single tokens, while rare words split into multiple tokens.
                        </div>
                    `,
                    code: `    # Convert the input text into token IDs using the tokenizer
    input_ids = tokenizer.encode(text)
    # The tokenizer encodes the text into a sequence of numerical token IDs.
    # Example: "Win a free iPhone now!" ‚Üí [1342, 567, 892, 401, 763, 2093]`
                },
                {
                    id: 3,
                    icon: "üìè",
                    title: "Check Context",
                    phase: "input-phase",
                    explanation: `
                        <h2>üìè Check Model's Context Length</h2>
                        <p>Every transformer model has a maximum context length - the maximum number of tokens it can process at once. For this GPT model, the context length is 1024 tokens, determined by the positional embedding layer.</p>
                        <p><strong>Technical Detail:</strong> The model's pos_emb (positional embedding) layer has shape [1024, embedding_dim]. The first dimension (1024) represents the number of positions the model can handle, which equals the context length.</p>
                        <div class="key-insight">
                            <strong>‚ö†Ô∏è Important Correction:</strong> The book uses shape[1], but this is incorrect. shape[0] gives the context length (1024), while shape[1] gives the embedding dimension (e.g., 768).
                        </div>
                    `,
                    code: `    # Determine the model's maximum supported context length
    supported_context_length = model.pos_emb.weight.shape[0]
    # self.pos_emb = nn.Embedding(cfg["context_length"], cfg["emb_dim"])
    # Here, context_length=1024, which means the model can process a maximum of 1024 tokens.
    # shape[0] correctly represents the number of positions (context length) the model can handle.`
                },
                {
                    id: 4,
                    icon: "‚úÇÔ∏è",
                    title: "Truncate",
                    phase: "processing-phase",
                    explanation: `
                        <h2>‚úÇÔ∏è Truncate Long Inputs</h2>
                        <p>If the input exceeds the maximum allowed length (either max_length or supported_context_length), we truncate it by keeping only the first N tokens. This prevents errors but means some information at the end might be lost.</p>
                        <p><strong>Example:</strong> If max_length=120 and input has 150 tokens, we keep only the first 120 tokens.</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> Truncation uses min() to respect both the user-specified max_length AND the model's hard limit (supported_context_length). This prevents dimension mismatch errors.
                        </div>
                    `,
                    code: `    # Truncate the input if it exceeds the maximum allowed length
    input_ids = input_ids[:min(max_length, supported_context_length)]
    # This ensures that the input does not exceed the model's context length.
    # If max_length=512 and supported_context_length=1024, but input has 600 tokens,
    # this keeps only the first 512 tokens.`
                },
                {
                    id: 5,
                    icon: "‚ûï",
                    title: "Padding",
                    phase: "processing-phase",
                    explanation: `
                        <h2>‚ûï Add Padding Tokens</h2>
                        <p>Neural networks process inputs in batches, and all sequences in a batch must have the same length. If our input is shorter than max_length, we add special padding tokens (ID: 50256) to the end until it reaches the target length.</p>
                        <p><strong>Example:</strong> If max_length=120 but input has only 85 tokens, we add 35 padding tokens.</p>
                        <p><strong>Why Padding Token = 50256?</strong> In GPT-2's tokenizer, 50256 is the &lt;|endoftext|&gt; token, which serves as both the padding token and end-of-sequence marker.</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> Padding enables batch processing: multiple texts can be processed simultaneously if they all have the same length. The model learns to ignore padding tokens during training.
                        </div>
                    `,
                    code: `    # Add padding if the input is shorter than max_length
    input_ids += [pad_token_id] * (max_length - len(input_ids))
    # Ensures all inputs have the same length for batch processing.
    # If max_length=120 and input_ids has only 85 tokens, this adds 35 padding tokens.`
                },
                {
                    id: 6,
                    icon: "üî¢",
                    title: "Create Tensor",
                    phase: "processing-phase",
                    explanation: `
                        <h2>üî¢ Convert to PyTorch Tensor</h2>
                        <p>Now we convert our Python list of token IDs into a PyTorch tensor - the data structure neural networks operate on. We also add a batch dimension using unsqueeze(0), transforming the shape from [120] to [1, 120], where 1 represents batch size.</p>
                        <p><strong>Why Batch Dimension?</strong> The model expects inputs in format [batch_size, sequence_length]. Even for a single text, we need batch_size=1.</p>
                        <p><strong>Why Move to Device?</strong> The tensor must be on the same device (CPU or GPU) as the model weights for computation.</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> unsqueeze(0) adds a dimension at position 0. Shape goes from [seq_len] to [1, seq_len]. This is crucial because PyTorch models expect batch-first inputs: [batch, sequence, features].
                        </div>
                    `,
                    code: `    # Convert token IDs into a PyTorch tensor and move it to the specified device (CPU/GPU)
    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)
    # torch.tensor(input_ids, device=device): Converts input into a PyTorch tensor and moves it to CPU/GPU.
    # .unsqueeze(0): Adds a batch dimension, making the shape (1, sequence_length), as the model expects batch inputs.`
                },
                {
                    id: 7,
                    icon: "üß†",
                    title: "Model Inference",
                    phase: "output-phase",
                    explanation: `
                        <h2>üß† Model Inference ‚Üí Extract Logits</h2>
                        <p>The model processes the input tensor through all its layers (embeddings, attention, feed-forward networks) and outputs logits - raw, unnormalized prediction scores for each class.</p>
                        <p><strong>Key Operation:</strong> [:, -1, :] extracts logits from the last token position only.</p>
                        <p><strong>Why Last Token?</strong> For classification tasks with GPT models, we use the last token's representation as a summary of the entire sequence. The model output shape is [batch, sequence, num_classes], and we extract [batch, num_classes] by taking [:, -1, :].</p>
                        <p><strong>What are Logits?</strong> Raw prediction scores before applying softmax. Higher values indicate stronger confidence for that class. For binary classification: [logit_not_spam, logit_spam].</p>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> torch.no_grad() disables gradient tracking during inference, reducing memory usage and speeding up computation. We only need gradients during training, not prediction.
                        </div>
                    `,
                    code: `    # Run inference without computing gradients (saves memory and speeds up inference)
    with torch.no_grad():
        logits = model(input_tensor)[:, -1, :]
        # The model outputs logits (raw prediction scores before applying softmax).
        # [:, -1, :] extracts the logits from the last token position.`
                },
                {
                    id: 8,
                    icon: "üéØ",
                    title: "Final Prediction",
                    phase: "output-phase",
                    explanation: `
                        <h2>üéØ Decode Prediction</h2>
                        <p>Finally, we convert the raw logits into a human-readable prediction. torch.argmax() finds the index of the highest logit value:</p>
                        <ul>
                            <li>If index = 0 ‚Üí "not spam"</li>
                            <li>If index = 1 ‚Üí "spam"</li>
                        </ul>
                        <p><strong>Example:</strong></p>
                        <ul>
                            <li>Logits: [-1.2, 3.4]</li>
                            <li>Argmax: 1 (because 3.4 &gt; -1.2)</li>
                            <li>Prediction: "spam"</li>
                        </ul>
                        <div class="key-insight">
                            <strong>Key Insight:</strong> Argmax performs <strong>hard classification</strong> - it always picks the class with the highest score, even if confidence is low. For probability scores, apply softmax(logits) first.
                        </div>
                    `,
                    code: `    # Get the predicted class label (0 = not spam, 1 = spam)
    predicted_label = torch.argmax(logits, dim=-1).item()
    # torch.argmax(logits, dim=-1): Finds the index of the highest logit value (most confident class).
    # .item(): Extracts the result as a standard Python integer.
    
    # Return "spam" if the predicted class is 1, otherwise return "not spam"
    return "spam" if predicted_label == 1 else "not spam"`
                }
            ]
        };

        const fullCodeText = `def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):
    """
    Classifies a given text message as either 'spam' or 'not spam' using a fine-tuned GPT model.

    Parameters:
    - text (str): The input message to classify.
    - model (torch.nn.Module): The fine-tuned GPT-based spam classification model.
    - tokenizer (Tokenizer): Tokenizer to convert text into tokenized input for the model.
    - device (torch.device): Specifies whether to run the model on CPU or GPU.
    - max_length (int, optional): The maximum length of input tokens allowed for classification.
    - pad_token_id (int, default=50256): The token ID used for padding short inputs.

    Returns:
    - str: "spam" if the message is classified as spam, otherwise "not spam".
    """

    model.eval()  # Sets the model to evaluation mode

    # Convert the input text into token IDs using the tokenizer
    input_ids = tokenizer.encode(text)
    
    # Determine the model's maximum supported context length
    supported_context_length = model.pos_emb.weight.shape[0]
    
    # Truncate the input if it exceeds the maximum allowed length
    input_ids = input_ids[:min(max_length, supported_context_length)]
    
    # Add padding if the input is shorter than max_length
    input_ids += [pad_token_id] * (max_length - len(input_ids))
    
    # Convert token IDs into a PyTorch tensor and move it to the specified device
    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)
    
    # Run inference without computing gradients
    with torch.no_grad():
        logits = model(input_tensor)[:, -1, :]
    
    # Get the predicted class label (0 = not spam, 1 = spam)
    predicted_label = torch.argmax(logits, dim=-1).item()
    
    # Return "spam" if the predicted class is 1, otherwise return "not spam"
    return "spam" if predicted_label == 1 else "not spam"`;

        // Initialize
        function init() {
            renderStepNavigation();
            renderCurrentStep();
            attachEventListeners();
        }

        // Render Step Navigation
        function renderStepNavigation() {
            const container = document.getElementById('stepNavigation');
            container.innerHTML = state.steps.map((step, index) => `
                <div class="step-card ${index === state.currentStep ? 'active ' + step.phase : ''}" data-step="${index}">
                    <div class="step-number">${step.id}</div>
                    <div class="step-icon">${step.icon}</div>
                    <div class="step-title">${step.title}</div>
                </div>
            `).join('');
        }

        // Render Current Step
        function renderCurrentStep() {
            const step = state.steps[state.currentStep];
            const example = state.examples[state.currentExample];

            // Update explanation
            document.getElementById('explanationArea').innerHTML = step.explanation;

            // Update code snippet
            const codeSnippet = document.getElementById('codeSnippet');
            codeSnippet.textContent = step.code;
            Prism.highlightElement(codeSnippet);

            // Update visualization
            renderVisualization(state.currentStep, example);

            // Update navigation
            renderStepNavigation();

            // Update buttons
            document.getElementById('prevBtn').disabled = state.currentStep === 0;
            document.getElementById('nextBtn').disabled = state.currentStep === state.steps.length - 1;
        }

        // Render Visualization
        function renderVisualization(stepIndex, example) {
            const svg = document.getElementById('visualization-svg');
            const text = example.text || "No text selected";
            const tokens = example.tokens;
            const tokenIds = example.tokenIds;
            const maxLength = 120;
            const truncatedLength = Math.min(tokenIds.length, maxLength);
            const paddingNeeded = Math.max(0, maxLength - truncatedLength);

            svg.innerHTML = ''; // Clear previous content

            switch(stepIndex) {
                case 0: // Input Text
                    svg.innerHTML = `
                        <rect x="50" y="100" width="500" height="200" fill="white" stroke="#ff9800" stroke-width="3" rx="10"/>
                        <foreignObject x="70" y="120" width="460" height="160">
                            <div xmlns="http://www.w3.org/1999/xhtml" style="font-size:14px; padding:10px; word-wrap:break-word; line-height:1.4;">
                                ${text.substring(0, 150)}${text.length > 150 ? '...' : ''}
                            </div>
                        </foreignObject>
                        <text x="300" y="330" text-anchor="middle" font-size="16" fill="#666">
                            Character count: ${text.length}
                        </text>
                    `;
                    break;

                case 1: // Tokenization
                    const displayTokens = tokens.slice(0, 8);
                    const displayIds = tokenIds.slice(0, 8);
                    svg.innerHTML = `
                        <text x="300" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Text ‚Üí Tokens ‚Üí Token IDs
                        </text>
                        ${displayTokens.map((token, i) => `
                            <g transform="translate(${50 + i * 65}, 80)">
                                <rect width="60" height="40" fill="#ffe0b2" stroke="#ff9800" rx="5"/>
                                <text x="30" y="25" text-anchor="middle" font-size="12" fill="#333">${token.substring(0, 8)}</text>
                            </g>
                            <text x="${80 + i * 65}" y="145" text-anchor="middle" font-size="20" fill="#ff9800">‚Üì</text>
                            <g transform="translate(${50 + i * 65}, 160)">
                                <rect width="60" height="40" fill="#bbdefb" stroke="#2196f3" rx="5"/>
                                <text x="30" y="25" text-anchor="middle" font-size="12" fill="#333">${displayIds[i]}</text>
                            </g>
                        `).join('')}
                        <text x="300" y="240" text-anchor="middle" font-size="14" fill="#666">
                            Total tokens: ${tokens.length}
                        </text>
                    `;
                    break;

                case 2: // Context Length
                    svg.innerHTML = `
                        <text x="300" y="40" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Model Context Length
                        </text>
                        <rect x="50" y="80" width="500" height="40" fill="#e3f2fd" stroke="#2196f3" stroke-width="2" rx="5"/>
                        <text x="300" y="105" text-anchor="middle" font-size="16" fill="#1976d2">
                            Maximum: 1024 tokens
                        </text>
                        <rect x="50" y="150" width="${(tokenIds.length / 1024) * 500}" height="40" fill="#c8e6c9" stroke="#4caf50" stroke-width="2" rx="5"/>
                        <text x="${50 + (tokenIds.length / 1024) * 250}" y="175" text-anchor="middle" font-size="14" fill="#2e7d32">
                            Current: ${tokenIds.length} tokens
                        </text>
                        <text x="300" y="240" text-anchor="middle" font-size="14" fill="#666">
                            pos_emb.weight.shape[0] = 1024
                        </text>
                    `;
                    break;

                case 3: // Truncation
                    const isTruncated = tokenIds.length > maxLength;
                    svg.innerHTML = `
                        <text x="300" y="40" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Truncation ${isTruncated ? '(Active)' : '(Not Needed)'}
                        </text>
                        <rect x="50" y="80" width="500" height="60" fill="${isTruncated ? '#ffebee' : '#e8f5e9'}" stroke="${isTruncated ? '#f44336' : '#4caf50'}" stroke-width="2" rx="5"/>
                        <text x="300" y="110" text-anchor="middle" font-size="14" fill="#333">
                            Input length: ${tokenIds.length} tokens
                        </text>
                        <text x="300" y="130" text-anchor="middle" font-size="14" fill="#333">
                            Max allowed: min(${maxLength}, 1024) = ${maxLength} tokens
                        </text>
                        ${isTruncated ? `
                            <text x="300" y="180" text-anchor="middle" font-size="16" fill="#f44336">
                                ‚úÇÔ∏è Keeping first ${maxLength} tokens
                            </text>
                            <text x="300" y="210" text-anchor="middle" font-size="14" fill="#999">
                                Discarding ${tokenIds.length - maxLength} tokens
                            </text>
                        ` : `
                            <text x="300" y="180" text-anchor="middle" font-size="16" fill="#4caf50">
                                ‚úì No truncation needed
                            </text>
                        `}
                    `;
                    break;

                case 4: // Padding
                    const actualTokens = Math.min(tokenIds.length, maxLength);
                    const padding = maxLength - actualTokens;
                    svg.innerHTML = `
                        <text x="300" y="40" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Padding ${padding > 0 ? '(Active)' : '(Not Needed)'}
                        </text>
                        <rect x="50" y="80" width="${(actualTokens / maxLength) * 400}" height="60" fill="#bbdefb" stroke="#2196f3" stroke-width="2" rx="5"/>
                        <text x="${50 + (actualTokens / maxLength) * 200}" y="115" text-anchor="middle" font-size="14" fill="#1976d2">
                            Actual tokens: ${actualTokens}
                        </text>
                        ${padding > 0 ? `
                            <rect x="${50 + (actualTokens / maxLength) * 400}" y="80" width="${(padding / maxLength) * 400}" height="60" fill="#f3e5f5" stroke="#9c27b0" stroke-width="2" rx="5" stroke-dasharray="5,5"/>
                            <text x="${50 + (actualTokens / maxLength) * 400 + (padding / maxLength) * 200}" y="115" text-anchor="middle" font-size="14" fill="#7b1fa2">
                                Padding: ${padding}
                            </text>
                        ` : ''}
                        <text x="300" y="180" text-anchor="middle" font-size="14" fill="#666">
                            Total length: ${maxLength} tokens
                        </text>
                        <text x="300" y="210" text-anchor="middle" font-size="12" fill="#999">
                            Padding token ID: 50256 (&lt;|endoftext|&gt;)
                        </text>
                    `;
                    break;

                case 5: // Tensor Creation
                    svg.innerHTML = `
                        <text x="300" y="40" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Python List ‚Üí PyTorch Tensor
                        </text>
                        <rect x="100" y="80" width="150" height="60" fill="#fff3e0" stroke="#ff9800" stroke-width="2" rx="5"/>
                        <text x="175" y="105" text-anchor="middle" font-size="12" fill="#e65100">Python List</text>
                        <text x="175" y="125" text-anchor="middle" font-size="14" fill="#333">[${maxLength}]</text>
                        <text x="280" y="115" text-anchor="middle" font-size="24" fill="#764ba2">‚Üí</text>
                        <rect x="350" y="80" width="150" height="60" fill="#e1f5fe" stroke="#00bcd4" stroke-width="2" rx="5"/>
                        <text x="425" y="105" text-anchor="middle" font-size="12" fill="#006064">PyTorch Tensor</text>
                        <text x="425" y="125" text-anchor="middle" font-size="14" fill="#333">[1, ${maxLength}]</text>
                        <text x="300" y="180" text-anchor="middle" font-size="14" fill="#666">
                            .unsqueeze(0) adds batch dimension
                        </text>
                        <text x="300" y="210" text-anchor="middle" font-size="12" fill="#999">
                            Shape: [batch_size, sequence_length]
                        </text>
                        <rect x="250" y="240" width="100" height="30" fill="#4caf50" stroke="#2e7d32" rx="5"/>
                        <text x="300" y="260" text-anchor="middle" font-size="12" fill="white">Device: CPU/GPU</text>
                    `;
                    break;

                case 6: // Model Forward Pass
                    svg.innerHTML = `
                        <defs>
                            <linearGradient id="grad1" x1="0%" y1="0%" x2="0%" y2="100%">
                                <stop offset="0%" style="stop-color:#00bcd4;stop-opacity:1" />
                                <stop offset="100%" style="stop-color:#0097a7;stop-opacity:1" />
                            </linearGradient>
                        </defs>
                        <text x="300" y="40" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Model Inference
                        </text>
                        
                        <!-- Input Tensor -->
                        <rect x="50" y="80" width="120" height="60" fill="#e3f2fd" stroke="#2196f3" stroke-width="2" rx="8"/>
                        <text x="110" y="105" text-anchor="middle" font-size="12" fill="#1976d2">Input Tensor</text>
                        <text x="110" y="125" text-anchor="middle" font-size="14" font-weight="bold" fill="#333">[1, ${maxLength}]</text>
                        
                        <!-- Arrow -->
                        <path d="M 170 110 L 220 110" stroke="#666" stroke-width="2" marker-end="url(#arrow)"/>
                        <defs>
                            <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                                <polygon points="0 0, 10 3, 0 6" fill="#666" />
                            </marker>
                        </defs>
                        
                        <!-- Model Box -->
                        <rect x="220" y="70" width="160" height="220" fill="url(#grad1)" stroke="#00bcd4" stroke-width="3" rx="12"/>
                        <text x="300" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="white">üß† GPT Model</text>
                        
                        <!-- Model Layers -->
                        <rect x="235" y="110" width="130" height="25" fill="rgba(255,255,255,0.2)" rx="4"/>
                        <text x="300" y="127" text-anchor="middle" font-size="10" fill="white">Embeddings</text>
                        
                        <rect x="235" y="145" width="130" height="25" fill="rgba(255,255,255,0.2)" rx="4"/>
                        <text x="300" y="162" text-anchor="middle" font-size="10" fill="white">Transformer 1-12</text>
                        
                        <rect x="235" y="180" width="130" height="25" fill="rgba(255,255,255,0.2)" rx="4"/>
                        <text x="300" y="197" text-anchor="middle" font-size="10" fill="white">Layer Norm</text>
                        
                        <rect x="235" y="215" width="130" height="25" fill="rgba(255,255,255,0.2)" rx="4"/>
                        <text x="300" y="232" text-anchor="middle" font-size="10" fill="white">Output Layer</text>
                        
                        <text x="300" y="270" text-anchor="middle" font-size="11" fill="white">[1, ${maxLength}, 2]</text>
                        
                        <!-- Arrow to extraction -->
                        <path d="M 380 180 L 420 180" stroke="#666" stroke-width="2" marker-end="url(#arrow)"/>
                        
                        <!-- Extraction -->
                        <rect x="420" y="150" width="130" height="60" fill="#fff3e0" stroke="#ff9800" stroke-width="2" rx="8"/>
                        <text x="485" y="172" text-anchor="middle" font-size="11" fill="#e65100">[:, -1, :]</text>
                        <text x="485" y="190" text-anchor="middle" font-size="10" fill="#666">Extract last</text>
                        <text x="485" y="205" text-anchor="middle" font-size="14" font-weight="bold" fill="#333">[1, 2]</text>
                        
                        <!-- Logits display -->
                        <rect x="200" y="320" width="200" height="50" fill="#e8f5e9" stroke="#4caf50" stroke-width="2" rx="8"/>
                        <text x="300" y="340" text-anchor="middle" font-size="11" fill="#2e7d32">Logits (raw scores)</text>
                        <text x="300" y="360" text-anchor="middle" font-size="12" fill="#333">[-1.2, 3.4]</text>
                        
                        <!-- torch.no_grad badge -->
                        <rect x="420" y="240" width="120" height="25" fill="#f3e5f5" stroke="#9c27b0" stroke-width="2" rx="4"/>
                        <text x="480" y="257" text-anchor="middle" font-size="9" fill="#6a1b9a">torch.no_grad()</text>
                    `;
                    break;

                case 7: // Final Prediction
                    const predictedLabel = example.label;
                    const logits = predictedLabel === "spam" ? [-1.2, 3.4] : [2.1, -0.8];
                    const probNotSpam = predictedLabel === "spam" ? 0.002 : 0.891;
                    const probSpam = predictedLabel === "spam" ? 0.998 : 0.109;
                    svg.innerHTML = `
                        <text x="300" y="35" text-anchor="middle" font-size="18" font-weight="bold" fill="#333">
                            Argmax ‚Üí Final Prediction
                        </text>
                        
                        <!-- Logits -->
                        <text x="300" y="70" text-anchor="middle" font-size="13" fill="#666">Input Logits</text>
                        <rect x="130" y="85" width="140" height="70" fill="#e3f2fd" stroke="#2196f3" stroke-width="2" rx="8"/>
                        <text x="200" y="110" text-anchor="middle" font-size="11" fill="#1976d2">Not Spam</text>
                        <text x="200" y="135" text-anchor="middle" font-size="16" font-weight="bold" fill="#333">${logits[0]}</text>
                        
                        <rect x="330" y="85" width="140" height="70" fill="#e3f2fd" stroke="#2196f3" stroke-width="2" rx="8"/>
                        <text x="400" y="110" text-anchor="middle" font-size="11" fill="#1976d2">Spam</text>
                        <text x="400" y="135" text-anchor="middle" font-size="16" font-weight="bold" fill="#333">${logits[1]}</text>
                        
                        <!-- Argmax arrow -->
                        <text x="300" y="180" text-anchor="middle" font-size="16" fill="#764ba2">‚Üì argmax()</text>
                        
                        <!-- Prediction result -->
                        <rect x="150" y="200" width="300" height="140" fill="${predictedLabel === 'spam' ? '#ffebee' : '#e8f5e9'}" 
                              stroke="${predictedLabel === 'spam' ? '#f44336' : '#4caf50'}" stroke-width="4" rx="12"/>
                        
                        <text x="300" y="230" text-anchor="middle" font-size="14" font-weight="600" fill="${predictedLabel === 'spam' ? '#c62828' : '#2e7d32'}">
                            FINAL PREDICTION
                        </text>
                        
                        <text x="300" y="265" text-anchor="middle" font-size="24" font-weight="bold" fill="${predictedLabel === 'spam' ? '#d32f2f' : '#388e3c'}">
                            ${predictedLabel.toUpperCase()}
                        </text>
                        
                        <text x="300" y="295" text-anchor="middle" font-size="13" fill="#666">
                            Confidence: ${predictedLabel === 'spam' ? '99.8%' : '89.1%'}
                        </text>
                        
                        <text x="300" y="320" text-anchor="middle" font-size="11" fill="#999">
                            Class ${predictedLabel === 'spam' ? 1 : 0} selected
                        </text>
                        
                        <!-- Probabilities -->
                        <text x="300" y="370" text-anchor="middle" font-size="10" fill="#999">
                            P(not spam)=${(probNotSpam * 100).toFixed(1)}%  |  P(spam)=${(probSpam * 100).toFixed(1)}%
                        </text>
                    `;
                    break;
            }
        }

        // Event Listeners
        function attachEventListeners() {
            // Example selection
            document.querySelectorAll('.example-btn').forEach(btn => {
                btn.addEventListener('click', (e) => {
                    const exampleIndex = parseInt(e.currentTarget.dataset.example);
                    state.currentExample = exampleIndex;
                    
                    // Update active state
                    document.querySelectorAll('.example-btn').forEach(b => b.classList.remove('active'));
                    e.currentTarget.classList.add('active');
                    
                    // Show/hide custom input
                    const customArea = document.getElementById('customInputArea');
                    if (exampleIndex === 4) {
                        customArea.classList.add('active');
                    } else {
                        customArea.classList.remove('active');
                    }
                    
                    renderCurrentStep();
                });
            });

            // Custom input
            const customInput = document.getElementById('customInput');
            const charCount = document.getElementById('charCount');
            customInput.addEventListener('input', (e) => {
                const text = e.target.value;
                charCount.textContent = `${text.length} characters`;
                
                // Update custom example
                state.examples[4].text = text;
                // Simple tokenization simulation
                state.examples[4].tokens = text.split(/\s+/).filter(t => t.length > 0);
                state.examples[4].tokenIds = state.examples[4].tokens.map(() => Math.floor(Math.random() * 50000));
                
                if (state.currentExample === 4) {
                    renderCurrentStep();
                }
            });

            // Step navigation
            document.getElementById('stepNavigation').addEventListener('click', (e) => {
                const stepCard = e.target.closest('.step-card');
                if (stepCard) {
                    state.currentStep = parseInt(stepCard.dataset.step);
                    renderCurrentStep();
                }
            });

            // Control buttons
            document.getElementById('prevBtn').addEventListener('click', () => {
                if (state.currentStep > 0) {
                    state.currentStep--;
                    renderCurrentStep();
                }
            });

            document.getElementById('nextBtn').addEventListener('click', () => {
                if (state.currentStep < state.steps.length - 1) {
                    state.currentStep++;
                    renderCurrentStep();
                }
            });

            const playBtn = document.getElementById('playBtn');
            playBtn.addEventListener('click', () => {
                if (state.isPlaying) {
                    // Pause
                    state.isPlaying = false;
                    playBtn.textContent = '‚ñ∂ Play';
                    clearInterval(state.playInterval);
                } else {
                    // Play
                    state.isPlaying = true;
                    playBtn.textContent = '‚è∏ Pause';
                    state.playInterval = setInterval(() => {
                        if (state.currentStep < state.steps.length - 1) {
                            state.currentStep++;
                            renderCurrentStep();
                        } else {
                            // End of steps
                            state.isPlaying = false;
                            playBtn.textContent = '‚ñ∂ Play';
                            clearInterval(state.playInterval);
                        }
                    }, 2000);
                }
            });

            // Modal
            const modal = document.getElementById('codeModal');
            const viewFullCodeBtn = document.getElementById('viewFullCodeBtn');
            const modalClose = document.getElementById('modalClose');

            viewFullCodeBtn.addEventListener('click', () => {
                modal.classList.add('active');
                const fullCode = document.getElementById('fullCode');
                
                // Define line ranges for each step
                const stepLineRanges = [
                    [1, 12],    // Step 1: Function definition and model.eval()
                    [14, 17],   // Step 2: Tokenization
                    [19, 21],   // Step 3: Context length
                    [23, 26],   // Step 4: Truncation
                    [28, 30],   // Step 5: Padding
                    [32, 34],   // Step 6: Tensor creation
                    [36, 38],   // Step 7: Model inference
                    [40, 44]    // Step 8: Prediction
                ];
                
                const currentRange = stepLineRanges[state.currentStep];
                
                // Set the code content
                fullCode.textContent = fullCodeText;
                
                // Apply Prism highlighting first
                Prism.highlightElement(fullCode);
                
                // After Prism, wrap the highlighted lines
                setTimeout(() => {
                    const lines = fullCode.innerHTML.split('\n');
                    const highlightedCode = lines.map((line, index) => {
                        const lineNum = index + 1;
                        if (lineNum >= currentRange[0] && lineNum <= currentRange[1]) {
                            return `<span class="highlight-line">${line}</span>`;
                        }
                        return line;
                    }).join('\n');
                    
                    fullCode.innerHTML = highlightedCode;
                    
                    // Scroll to highlighted section
                    setTimeout(() => {
                        const highlightedLine = document.querySelector('.highlight-line');
                        if (highlightedLine) {
                            highlightedLine.scrollIntoView({ behavior: 'smooth', block: 'center' });
                        }
                    }, 100);
                }, 50);
            });

            modalClose.addEventListener('click', () => {
                modal.classList.remove('active');
            });

            modal.addEventListener('click', (e) => {
                if (e.target === modal) {
                    modal.classList.remove('active');
                }
            });

            // Keyboard navigation
            document.addEventListener('keydown', (e) => {
                if (e.key === 'ArrowLeft' && state.currentStep > 0) {
                    state.currentStep--;
                    renderCurrentStep();
                } else if (e.key === 'ArrowRight' && state.currentStep < state.steps.length - 1) {
                    state.currentStep++;
                    renderCurrentStep();
                } else if (e.key === 'Escape') {
                    modal.classList.remove('active');
                }
            });
        }

        // Initialize on load
        init();
    </script>
</body>
</html>