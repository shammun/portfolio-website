{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "\n",
    "This notebook is based on the book **[\"Build a Large Language Model (From Scratch)\"](https://www.manning.com/books/build-a-large-language-model-from-scratch)** by **Sebastian Raschka**, published by Manning Publications.\n",
    "\n",
    "- [Book on Manning](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [GitHub Repository](https://github.com/rasbt/LLMs-from-scratch)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0J74Yydt1-z"
   },
   "source": [
    "# Basics of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTimly6bt1-0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386087,
     "user_tz": 300,
     "elapsed": 4035,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "acd07e5d-0e5c-4e9c-d8fd-59b515ceea9f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ap0JwNXRt1-1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 39,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "fd10e05f-6793-4ef4-fe32-31cb64821fb8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64v9wk1Zt1-1"
   },
   "source": [
    "## Understanding tensors"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "tensor0d = torch.tensor(1)\n",
    "tensor1d = torch.tensor([1,2,3])\n",
    "tensor2d = torch.tensor([[1, 2, 3], [3, 4, 5]])\n",
    "tensor3d = torch.tensor([[[1,2,3,4], [5,6,7,8], [1,1,1,1]],\n",
    "                         [[7,8,9,10], [11,12,13,14], [2,2,2,2]]])"
   ],
   "metadata": {
    "id": "xd4IrlEauNVS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Shape of tensor2d:\", tensor2d.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m0lDxS-vKJq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 36,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "4f78dc32-2347-4930-fd91-0f5aae335b1f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of tensor2d: torch.Size([2, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Shape of tensor3d:\", tensor3d.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57VBPnt8vWCh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 33,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "cad74415-4e43-478d-a51c-f1ed95b35819"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of tensor3d: torch.Size([2, 3, 4])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor0d.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCAFNNhjvsI8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 30,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "534513a7-d34d-4834-e315-5e681280a5a6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor1d.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdktYu1avz5i",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 28,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "52df1a8d-6b73-4a3e-f517-b4ff2e37aa02"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor3d.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8xy3crrv1ga",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 26,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "28de6a6c-0c6f-44fd-ea44-2ccceb0af1d9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"If we create tensors from Python **floats**, PyTorch creates tensors with a 32-bit precision by default:\""
   ],
   "metadata": {
    "id": "NYh6IdGLvVIB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(floatvec.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K98O918NwKOS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 23,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "c705f36b-4657-426f-c79e-1f17c2866b36"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.float32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rhiMn2nt1-1"
   },
   "source": [
    "  A 32-bit floating-point number offers sufficient precision for most deep learning tasks. \"It is possible to change the precision using a tensor’s **.to** method\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "floatvec = tensor1d.to(torch.float32)\n",
    "print(floatvec.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FFhIE6wwfSQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 21,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "605bf37f-2cd2-44ff-fbd9-5a4d308dc02a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.float32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Common PyTorch tensor operations"
   ],
   "metadata": {
    "id": "jcVfWbLcw8oK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWxyyx1SwxXS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386088,
     "user_tz": 300,
     "elapsed": 19,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "c4f2775b-e6bc-4fc1-f144-d5d9f60c9d23"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can reshape the tensor into a 3 × 2 tensor."
   ],
   "metadata": {
    "id": "8Z7Cor_oxGXb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.reshape(3, 2))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu-yndbCw_Wi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386089,
     "user_tz": 300,
     "elapsed": 18,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "a9c2506e-9527-450f-ccfc-0429d3e4dcbb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "More common method for reshaping in PyTorch is **.view()**."
   ],
   "metadata": {
    "id": "g_GanHIexQ1h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.view(3, 2))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im7NEiFZxMzQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386089,
     "user_tz": 300,
     "elapsed": 15,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "da1752c4-0e18-48eb-b47b-504ee2b5a751"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\".view() requires the original data to be contiguous and will fail if it isn’t, whereas .reshape() will work regardless, copying the data if necessary to ensure the desired shape\""
   ],
   "metadata": {
    "id": "mZpDrcCLxjGD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transpose -- .T"
   ],
   "metadata": {
    "id": "1Vn8RxWqxoS8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HThAOiy7xaFx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386089,
     "user_tz": 300,
     "elapsed": 12,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "9c3458ed-780d-4b96-ecc3-6a7bf94bc9cd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBszwLFRxu-5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386089,
     "user_tz": 300,
     "elapsed": 11,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "f237258c-0c82-4ae7-b482-2aa19bb74eca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.T)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oxo5dBKqxxl5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386089,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "8a367df9-7190-43ce-e50d-f0fc9c250aba"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4],\n",
      "        [3, 5]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLXGWCfux1vy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386391,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "99d230fd-31e0-4b83-fdbd-04a649a8ecae"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This command **.T** gives transpose matrix but does npt change the original matrix unless you save it to the original."
   ],
   "metadata": {
    "id": "kMo-C_Y5x9SR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Matrix multiplication -- .matmul()"
   ],
   "metadata": {
    "id": "nN1KkQp_yNCU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d.matmul(tensor2d.T))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ff7O_4Btx5hM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878386761,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "e48fb54c-bed2-4b82-e2c6-031c505c111c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[14, 26],\n",
      "        [26, 50]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Matrix multiplication -- **@**"
   ],
   "metadata": {
    "id": "7jg7i0U5yZzL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tensor2d @ tensor2d.T)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SY7JIFFmyWoK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878387123,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "1bc2f5be-2e92-43e9-e280-6fd77c91f230"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[14, 26],\n",
      "        [26, 50]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computation Graph"
   ],
   "metadata": {
    "id": "o8NpGvNs1_m5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A logistic regression forward pass"
   ],
   "metadata": {
    "id": "9rtZ5JUYAeMW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2])\n",
    "b = torch.tensor([0.0])\n",
    "z = x1 * w1 + b\n",
    "a = torch.sigmoid(z)\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "print(loss)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjORSpBSyiy4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878387936,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "5d66680f-0ae0-4d0d-ac97-2fc17d504836"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing gradients via autograd"
   ],
   "metadata": {
    "id": "3WaKAmmTAiTf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b = grad(loss, b, retain_graph=True)\n",
    "\n",
    "print(grad_L_w1)\n",
    "print(grad_L_b)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2JVGKbI2chR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878388252,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "416eae25-d8f3-4bee-a8d3-57225c95db60"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(grad_L_w1[0])\n",
    "print(grad_L_b[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJSq22ryBvrM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878388252,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "172132c2-8751-4b99-fbf8-adf4047509ac"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " \"we can call **.backward** on the loss, and PyTorch will compute the gradients of all the leaf nodes in the graph, which will be stored via the tensors’ **.grad** attributes:\""
   ],
   "metadata": {
    "id": "yMNyR25mCNYf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "id": "S3ucqayyB4mh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(w1.grad)\n",
    "print(b.grad)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uNSRREoCXZt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878389109,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "8c7bb8b4-0c5c-46ac-f9f2-931e5dafb440"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing multilayer neural networks"
   ],
   "metadata": {
    "id": "PyriNrmHD6sI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A multilayer perceptron with two hidden layers"
   ],
   "metadata": {
    "id": "hxyR7pcNEFFP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "  def __init__(self, num_inputs, num_outputs):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layers = torch.nn.Sequential(\n",
    "        # 1st hidden layer -- 30 nodes in the hidden layer\n",
    "        torch.nn.Linear(num_inputs, 30),\n",
    "        torch.nn.ReLU(),\n",
    "\n",
    "        # 2nd hidden layer -- 20 nodes or hidden units\n",
    "        torch.nn.Linear(30, 20),\n",
    "        torch.nn.ReLU(),\n",
    "\n",
    "        # output layer\n",
    "        torch.nn.Linear(20, num_outputs)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    logits = self.layers(x)\n",
    "    return logits"
   ],
   "metadata": {
    "id": "KUaJRXFWCbeg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate a new neural network object"
   ],
   "metadata": {
    "id": "cdmeLg7tFOhv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = NeuralNetwork(50, 3) # Number of inputs is 50 and number of outputs is 3"
   ],
   "metadata": {
    "id": "r7rqip3hFLiE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEQYIEIeFY-E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878390423,
     "user_tz": 300,
     "elapsed": 5,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "81c37083-1aa2-48d9-e32e-41aa256c1754"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Total number of trainable parameters of this model"
   ],
   "metadata": {
    "id": "03cf8bcAFwzz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable parameters:\", num_params)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnEcZFnrFaZY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878391644,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "9523b463-fecc-430d-d963-9efb1dca35aa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of trainable parameters: 2213\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight of layers"
   ],
   "metadata": {
    "id": "l5ve5l2IGS7W"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Weight of the first Linear layer"
   ],
   "metadata": {
    "id": "5DhgFE2bGWe4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.layers[0].weight)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfwyqUVXGMR8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878391974,
     "user_tz": 300,
     "elapsed": 6,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "4df8d307-0ceb-4e2e-b591-7df3e5eae22a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0902, -0.0872, -0.0647,  ...,  0.0258, -0.0511,  0.0559],\n",
      "        [ 0.0193,  0.0288, -0.0526,  ...,  0.0612,  0.0223, -0.0825],\n",
      "        [-0.0870, -0.0267, -0.1318,  ...,  0.1013,  0.0416, -0.0316],\n",
      "        ...,\n",
      "        [-0.0869,  0.1370, -0.1022,  ...,  0.1283, -0.0957, -0.0624],\n",
      "        [ 0.0624,  0.0079, -0.0554,  ...,  0.0250, -0.0850, -0.1238],\n",
      "        [ 0.0598, -0.0201, -0.1021,  ..., -0.0553, -0.0375,  0.0615]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.layers[0].weight.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4k7oEVyGeKt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878391975,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "ab6874f7-b91d-4361-91f3-25fc711aa390"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"We can make the random number initialization reproducible by seeding PyTorch’s random number generator via **manual_seed**\""
   ],
   "metadata": {
    "id": "OZupoPPmG1yE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKTbZ019GkSV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878392973,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "732a02f8-7ee9-4973-881d-c689191cff93"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "X = torch.rand((1, 50)) # tensor of shape (1, 50) where each element is a random number in\n",
    "# [0,1)\n",
    "#  generates a tensor filled with random values sampled from a uniform distribution\n",
    "# [0, 1) -- include 0 but exclude 1\n",
    "out = model(X)\n",
    "print(out)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcHcwqvrHDgu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878393299,
     "user_tz": 300,
     "elapsed": 7,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "3c6b899b-f70d-4d6f-b26a-533eea92b285"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFJlZituONC6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878393299,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "cb38ec93-2c84-42b4-c4d0-58f8f950d3a6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
       "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274,\n",
       "         0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745, 0.6584, 0.2775,\n",
       "         0.8573, 0.8993, 0.0390, 0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340,\n",
       "         0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318, 0.4545, 0.9737, 0.4606,\n",
       "         0.5159, 0.4220, 0.5786, 0.9455, 0.8057]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"In the preceding code, we generated a single random training example X as a toy input (note that our network expects 50-dimensional feature vectors) and fed it to the model, returning three scores. When we call model(x), it will automatically execute the forward pass of the model.\""
   ],
   "metadata": {
    "id": "XzZfWipbO7kf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"When we use a model for inference (for instance, making predictions) rather than training, the best practice is to use the **torch.no_grad()** context manager. This tells PyTorch that it doesn’t need to keep track of the gradients, which can result in significant savings in memory and computation:\""
   ],
   "metadata": {
    "id": "BwQKsWm5PTT9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "  out = model(X)\n",
    "print(out)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agh_fCtyOlBG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878393580,
     "user_tz": 300,
     "elapsed": 5,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "4fdb0d08-8d38-49b2-dfb8-7b5ed93f6fa7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"So, if we want to compute class-membership probabilities for our predictions, we have to call the softmax function explicitly:\""
   ],
   "metadata": {
    "id": "H-W277ukPyJD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "  out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIyzF3utPfRS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735878394818,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "b4925f32-5e0f-4487-bc6d-0225203ea42b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Why dim=1 in This Code?\n",
    "##### Input to the Model\n",
    "- X has a shape of (1, 50), meaning it has 1 row and 50 features (or inputs).\n",
    "- model(X) produces logits, likely for a classification problem.\n",
    "\n",
    "##### Output of model(X)\n",
    "- Assuming model(X) outputs a tensor of shape (batch_size, num_classes):\n",
    "\n",
    "  - batch_size: Number of input samples (1 in this case).\n",
    "  - num_classes: Number of possible classes for classification.\n",
    "- For example, if model(X) outputs a tensor of shape (1, 10), this corresponds to:\n",
    "\n",
    "  - 1 sample in the batch.\n",
    "  - 10 raw scores (logits) for 10 possible classes.\n",
    "##### dim=1 Meaning\n",
    "- Dimension 1 corresponds to the second axis (columns) in a 2D tensor. Applying softmax along dim=1 means:\n",
    "  - For each row (sample) in the tensor, the raw scores (logits) in all columns (classes) are normalized to sum to 1.\n",
    "\n",
    "##### Why Normalize Along dim=1?\n",
    "- In classification problems, the softmax is applied across the class dimension (columns) to produce probabilities for each class.\n",
    "- Each row in the output tensor will represent the probability distribution for one sample.\n"
   ],
   "metadata": {
    "id": "EDUARVozQs_2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up efficient data loaders"
   ],
   "metadata": {
    "id": "ohLsXXD1dY2k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset of five observastions for training data for two features. Also create a tensor containing the corresponding class labels: three examples belonging to class 0, and two examples belonging to class 1. In addition, make a test set consisting of two entries."
   ],
   "metadata": {
    "id": "CpiwvKD1eLlS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "X_test = torch.tensor([[-0.8, 2.8],\n",
    "                       [2.6, -1.6],])\n",
    "y_test = torch.tensor([0, 1])"
   ],
   "metadata": {
    "id": "3B_NDIvLP-Kl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**PyTorch requires that class labels start with label 0**"
   ],
   "metadata": {
    "id": "44hT784peg11"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a custom dataset class"
   ],
   "metadata": {
    "id": "y29ibvBNeqVA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.features = X\n",
    "    self.labels = y\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    one_x = self.features[index]\n",
    "    one_y = self.labels[index]\n",
    "    return one_x, one_y\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.labels.shape[0]\n",
    "\n",
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ],
   "metadata": {
    "id": "1X8sqGBXeFkP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(train_ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQZl0ZVBf-BO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735879830571,
     "user_tz": 300,
     "elapsed": 254,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "116c2f93-d848-4937-d4d9-6409a3a98fbb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After defining PyTorch Dataset class, we can use it for our toy dataset using PyTorch’s **DataLoader** class to sample from it"
   ],
   "metadata": {
    "id": "bEqVg5O9kGMJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Instantiating data loaders"
   ],
   "metadata": {
    "id": "ttLDEgFDkqp5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_ds,\n",
    "                          batch_size = 2,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0\n",
    "                          )\n",
    "# The num_workers parameter in the DataLoader specifies the number of worker\n",
    "# processes used for loading data. It controls how many separate subprocesses\n",
    "# are used to fetch data in parallel while training or testing a model.\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "metadata": {
    "id": "rtw6w7IxgCnx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterating over data"
   ],
   "metadata": {
    "id": "wCYuzJrslhgx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "  print(f\"Vatch {idx+1}:\", x, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v0mz4z8lbF1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735881481835,
     "user_tz": 300,
     "elapsed": 288,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "b44f9344-467f-4f49-8f76-d85e22c89c95"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vatch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Vatch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Vatch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set `drop_last=True` to drop the last batch in each epoch."
   ],
   "metadata": {
    "id": "rUZnf1ipmc_I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ],
   "metadata": {
    "id": "xL5vKBvTmVvv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "  print(f\"Batch {idx+1}:\", x, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGEMyWVBmv8c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735881634188,
     "user_tz": 300,
     "elapsed": 260,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "e7b4db4c-c9ec-4bd6-84e9-66eb362e223d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A typical training loop"
   ],
   "metadata": {
    "id": "HqOvx_gzq-j5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "    logits = model(features)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "          f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "          f\" | Trrain Loss: {loss:.2f}\")\n",
    "    model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJ28sQbHm69F",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735883202087,
     "user_tz": 300,
     "elapsed": 3868,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "49be9004-c94a-4c46-911d-3ac773e0425e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Trrain Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Trrain Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Trrain Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Trrain Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Trrain Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Trrain Loss: 0.00\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate the model with 2 input features and 2 output classes\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "\n",
    "# Define an optimizer (Stochastic Gradient Descent) with a learning rate of 0.5\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "num_epochs = 3\n",
    "\n",
    "# Simulated data loader (you need to replace `train_loader` with your actual data loader)\n",
    "# train_loader is expected to yield batches of (features, labels)\n",
    "for epoch in range(num_epochs):  # Loop over each epoch\n",
    "    model.train()  # Set the model to training mode (important for layers like dropout, batch norm)\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):  # Loop over batches of data\n",
    "        # Forward pass: compute predicted logits (unnormalized scores)\n",
    "        logits = model(features)\n",
    "\n",
    "        # Compute the loss using cross-entropy\n",
    "        # Cross-entropy is suitable for classification tasks\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        # Zero out gradients to prevent accumulation from previous steps\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradients of the loss w.r.t model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters based on computed gradients\n",
    "        optimizer.step()\n",
    "        #  The optimizer.step() method will use the gradients to update the model\n",
    "        # parameters to minimize the loss. In the case of the SGD optimizer, this\n",
    "        # means multiplying the gradients with the learning rate and adding the\n",
    "        # scaled negative gradient to the parameters.\n",
    "\n",
    "        # Logging: Print training progress\n",
    "        # f-strings are used for formatting the output to display relevant info clearly\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"  # Current epoch and total epochs\n",
    "              f\" | Batch {batch_idx+1:03d}/{len(train_loader):03d}\"  # Current batch and total batches\n",
    "              f\" | Train Loss: {loss.item():.2f}\")  # Training loss for the current batch\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode (no dropout, batch norm)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ugktp4Pus43T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735883768663,
     "user_tz": 300,
     "elapsed": 297,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "85a0ab2b-e1b7-46c6-ad1c-aca04c58bf6d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.69\n",
      "Epoch: 001/003 | Batch 002/002 | Train Loss: 0.49\n",
      "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.34\n",
      "Epoch: 002/003 | Batch 002/002 | Train Loss: 0.20\n",
      "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.04\n",
      "Epoch: 003/003 | Batch 002/002 | Train Loss: 0.22\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Formatter Used in Logging:\n",
    "\n",
    "  - `f\"{epoch+1:03d}\"`: Ensures that the epoch number is formatted as a 3-digit number with leading zeros, e.g., \"001\".\n",
    "  - `len(train_loader)`: Displays the total number of batches in the data loader.\n",
    "  - `loss.item()`: Converts the tensor loss value to a Python float for display purposes.\n",
    "  - `.2f`: Formats the loss to two decimal places for readability.\n",
    "\n",
    "2. Why `model.train()` and `model.eval()` Are Used:\n",
    "\n",
    "  - `model.train()`: Ensures that the model behaves appropriately during training, e.g., enabling dropout and batch normalization layers.\n",
    "  - `model.eval()`: Ensures the model behaves appropriately during evaluation or inference, disabling dropout and using running statistics for batch normalization. It is misplaced in this code and should be used outside the training loop when validating or testing.\n",
    "\n",
    "3. Why `optimizer.zero_grad()` Is Used:\n",
    "\n",
    "  - Gradients accumulate in PyTorch by default. Before computing the new gradients, we need to zero them out to prevent incorrect updates.\n",
    "\n",
    "4. Purpose of Cross-Entropy Loss:\n",
    "\n",
    "  - Cross-entropy loss is suitable for classification tasks, measuring the difference between predicted probabilities and actual class labels.\n",
    "\n",
    "5. Learning Rate:\n",
    "\n",
    "  - The learning rate (`lr=0.5`) determines the step size for parameter updates. A high learning rate can cause the model to converge quickly or fail to converge, while a small one may slow training."
   ],
   "metadata": {
    "id": "iIy-zqZ3twRh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Why optimizer.zero_grad() Is Used\n",
    "Before computing gradients for a new batch, you need to clear the old gradients to ensure they don’t interfere with the new ones.\n",
    "\n",
    "**Without** `optimizer.zero_grad()`:\n",
    "  - Gradients will accumulate over multiple forward-backward passes, leading to incorrect parameter updates."
   ],
   "metadata": {
    "id": "a-G-oL_oumzc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making Predictions"
   ],
   "metadata": {
    "id": "RQy3l5PpvXrK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After we have trained the model, we can use it to make predictions:"
   ],
   "metadata": {
    "id": "qcG23Cd2vbL-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  outputs = model(X_train)\n",
    "print(outputs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-rf8hostvea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735883904879,
     "user_tz": 300,
     "elapsed": 5,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "60996193-dc1a-4431-bd79-b1263a11f2bb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 2.4929, -1.8742],\n",
      "        [ 2.2958, -1.7236],\n",
      "        [ 1.9967, -1.4961],\n",
      "        [-1.5813,  1.3215],\n",
      "        [-1.7966,  1.5170]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the model to evaluation mode\n",
    "# This ensures that certain layers, like dropout and batch normalization, behave appropriately during evaluation.\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations using torch.no_grad()\n",
    "# Explanation:\n",
    "# - Gradient calculations are not needed during evaluation or inference.\n",
    "# - Disabling gradients reduces memory usage and speeds up computation.\n",
    "# - This is especially useful when you are only interested in forward pass outputs.\n",
    "with torch.no_grad():\n",
    "    # Perform a forward pass through the model using the training data (X_train)\n",
    "    # Explanation:\n",
    "    # - The model takes X_train as input and produces outputs.\n",
    "    # - This step generates predictions or activations from the model without updating weights.\n",
    "    outputs = model(X_train)\n",
    "\n",
    "# Print the outputs generated by the model\n",
    "# Explanation:\n",
    "# - This displays the predictions or activations generated from the forward pass.\n",
    "# - Useful for verifying the model's output during evaluation.\n",
    "print(outputs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypSVC6-hvlRE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884068252,
     "user_tz": 300,
     "elapsed": 1204,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "2d9e664c-e521-41e2-9963-b58f2441956d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 2.4929, -1.8742],\n",
      "        [ 2.2958, -1.7236],\n",
      "        [ 1.9967, -1.4961],\n",
      "        [-1.5813,  1.3215],\n",
      "        [-1.7966,  1.5170]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set print options to avoid scientific notation for better readability\n",
    "# Explanation:\n",
    "# - By default, PyTorch prints tensors in scientific notation for small or large values.\n",
    "# - Setting `sci_mode=False` ensures the output is displayed in standard decimal format.\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "# Apply the softmax function to the outputs along the specified dimension (dim=1)\n",
    "# Explanation:\n",
    "# - Softmax converts raw model outputs (logits) into probabilities.\n",
    "# - It normalizes the logits into a range between 0 and 1, and the sum of values across the specified dimension equals 1.\n",
    "# - `dim=1` specifies that softmax operates across the second dimension (columns) of the tensor.\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "\n",
    "# Print the probabilities generated by the softmax function\n",
    "# Explanation:\n",
    "# - This displays the normalized probabilities for each input in the batch.\n",
    "# - Each row in the output tensor represents the probabilities for the two classes (binary classification in this case).\n",
    "print(probas)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KncLSxBxaoH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884387660,
     "user_tz": 300,
     "elapsed": 303,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "3b3c5568-a822-4969-e1ef-f22ce638a417"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.9875, 0.0125],\n",
      "        [0.9824, 0.0176],\n",
      "        [0.9705, 0.0295],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.0351, 0.9649]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtain class membership probabilities using `softmax`"
   ],
   "metadata": {
    "id": "oqYl9vXpwZQg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nKDZLcjwM-e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884178181,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "81388d75-c666-473c-da7d-436350723f1d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.9875, 0.0125],\n",
      "        [0.9824, 0.0176],\n",
      "        [0.9705, 0.0295],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.0351, 0.9649]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Softmax Probabilities:\n",
    "\n",
    "  - Each row corresponds to a single input sample in the batch.\n",
    "  - Each element in a row represents the predicted probability of the sample belonging to a specific class.\n",
    "  - The sum of probabilities in each row is always 1 due to the normalization property of softmax.\n",
    "\n",
    "2. Example Analysis:\n",
    "\n",
    "  - Row 1: [0.9875, 0.0125]:\n",
    "    - The model is 98.75% confident that the first sample belongs to Class 0.\n",
    "    - The probability for Class 1 is only 1.25%, suggesting a strong preference for Class 0.\n",
    "  - Row 4: [0.0520, 0.9480]:\n",
    "    - The model is 94.80% confident that the fourth sample belongs to Class 1.\n",
    "    - It predicts Class 1 with high certainty compared to Class 0.\n",
    "\n",
    "3. Interpreting the Results:\n",
    "\n",
    "  - High Values: When one value in a row is much larger than the other, the model is confident about its prediction.\n",
    "  - Low Certainty: If the values in a row are closer (e.g., [0.6, 0.4]), the model is less confident about its prediction.\n",
    "\n",
    "#### Why Use Softmax:\n",
    "Softmax is often used in classification problems because it provides interpretable probabilities, allowing you to assess the model's confidence in its predictions. These probabilities can be used to make decisions or evaluate model performance."
   ],
   "metadata": {
    "id": "DPmHj6gzw5T_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"We can convert these values into class label predictions using PyTorch’s argmax function, which returns the index position of the highest value in each row if we set `dim=1`\""
   ],
   "metadata": {
    "id": "2Ukh1RFHxt_w"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUj2L4EYwoC0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884501759,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "d7d36834-ec4a-40f1-8c90-20e169bfcb69"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"Note that it is unnecessary to compute softmax probabilities to obtain the class labels. We could also apply the argmax function to the logits (outputs) directly:\""
   ],
   "metadata": {
    "id": "vh2uXXZRyBK5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8Nam5QOx2-i",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884588456,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "5067f1e6-8ce2-42af-f4b0-8c3a7a194402"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " \"Since the training dataset is relatively small, we could compare it to the true training labels by eye and see that the model is 100% correct.\""
   ],
   "metadata": {
    "id": "ku334NpWyVuK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictions == y_train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofcFKHgIyMNz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884609069,
     "user_tz": 300,
     "elapsed": 447,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "5e3f2e54-ecb9-4a7c-a9c8-d94632d071ca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Number of correct predictions -- using `torch.sum()`"
   ],
   "metadata": {
    "id": "iabdNJuNydrB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.sum(predictions == y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q7gB2SIyREL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735884700468,
     "user_tz": 300,
     "elapsed": 291,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "98505825-f018-47e4-efe0-9f9c58f82919"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generalize the computation of the prediction accuracy"
   ],
   "metadata": {
    "id": "CLa-0hNpyxpB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "  model = model.eval()\n",
    "  correct = 0.0\n",
    "  total_examples = 0\n",
    "\n",
    "  for idx, (features, labels) in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "      logits = model(features)\n",
    "\n",
    "    predictions  = torch.argmax(logits, dim=1)\n",
    "    compare = labels == predictions\n",
    "    correct += torch.sum(compare)\n",
    "    total_examples += len(compare)\n",
    "\n",
    "  return (correct / total_examples).item()"
   ],
   "metadata": {
    "id": "Fr-BPa5FynYG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(compute_accuracy(model, train_loader))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmtsBHKP4pzJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735886306369,
     "user_tz": 300,
     "elapsed": 348,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "9077336c-dc19-4773-e4b6-ff7dbfcfe197"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can apply the function to the test set:"
   ],
   "metadata": {
    "id": "MEcU5iwv4-Yv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSlFLOii4vf5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735886385619,
     "user_tz": 300,
     "elapsed": 295,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "f8115d65-88aa-4a68-ef81-4f5481476fae"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving and loading models"
   ],
   "metadata": {
    "id": "QfRRV2yR5RLS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BHT_otq5C9T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735888517884,
     "user_tz": 300,
     "elapsed": 29591,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "61cf044f-a5bf-43c4-905f-265b3c18dcc0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "path = \"/content/drive/My Drive/LLM from Scratch/model.pth\""
   ],
   "metadata": {
    "id": "N0e9LytqBaRT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), path)"
   ],
   "metadata": {
    "id": "u7RTv7gdBEXg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "`.pth` and `.pt` are the most common file extensions for saving files."
   ],
   "metadata": {
    "id": "9aschHIIBzqI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Optimizing training performance with GPUs"
   ],
   "metadata": {
    "id": "v7sGvDoxCBRH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PQ4SHlTBpaQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735888754437,
     "user_tz": 300,
     "elapsed": 6,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "8cd07485-db32-44c4-93a9-ad01d0423087"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_1 = torch.tensor([1., 2., 3.])\n",
    "tensor_2 = torch.tensor([4., 5., 6.])\n",
    "print(tensor_1 + tensor_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqbVPA7rCFVu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735888814257,
     "user_tz": 300,
     "elapsed": 262,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "67b85314-7c9e-4265-e265-b4ff158372a6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " Transfer these tensors onto a GPU and perform the addition."
   ],
   "metadata": {
    "id": "Dt5k9RyeCYiH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tensor_1 = tensor_1.to(\"cuda\")\n",
    "tensor_2 = tensor_2.to(\"cuda\")\n",
    "print(tensor_1 + tensor_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwczfraPCT3u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735888900399,
     "user_tz": 300,
     "elapsed": 800,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "11356de2-cee5-424a-d2e6-a52830f4f739"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single-GPU training"
   ],
   "metadata": {
    "id": "R5Xr0AkdC3AX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  model.train()\n",
    "  for batch_idx, (feature, labels) in enumerate(train_loader):\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    logits = model(features)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "    f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "    f\" | Ttrain/Val loss: {loss:.2f}\")\n",
    "  model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J35buhH4CoxS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1735889374796,
     "user_tz": 300,
     "elapsed": 523,
     "user": {
      "displayName": "Shammunul Islam",
      "userId": "06152927859503822137"
     }
    },
    "outputId": "1424cc40-5097-48d8-b5f9-9c925d128b88"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Ttrain/Val loss: 0.81\n",
      "Epoch: 001/003 | Batch 001/002 | Ttrain/Val loss: 1.29\n",
      "Epoch: 002/003 | Batch 000/002 | Ttrain/Val loss: 0.65\n",
      "Epoch: 002/003 | Batch 001/002 | Ttrain/Val loss: 1.20\n",
      "Epoch: 003/003 | Batch 000/002 | Ttrain/Val loss: 0.70\n",
      "Epoch: 003/003 | Batch 001/002 | Ttrain/Val loss: 0.63\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"We can use `.to(\"cuda\")` instead of `device = torch.device(\"cuda\")`. Transferring a tensor to \"cuda\" instead of `torch.device(\"cuda\")` works as well and is shorter (see section A.9.1). We can also modify the statement, which will make the same code executable on a CPU if a GPU is not available\"."
   ],
   "metadata": {
    "id": "bnghhXefEq3A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "qpBGDpmaEcrt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nwc13MgaE7dw"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}